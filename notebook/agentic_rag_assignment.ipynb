{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b64baed3",
   "metadata": {},
   "source": [
    "### Config the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860e2fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96cff3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import operator\n",
    "from typing import List\n",
    "from pydantic import BaseModel , Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from typing import TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langgraph.graph import StateGraph,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fcef890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your OpenAI API key here if not already set\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\") \n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138962f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_name):\n",
    "    if model_name == \"gpt-4o\":\n",
    "        return ChatOpenAI(model=model_name, temperature=0)\n",
    "    elif model_name == \"text-embedding-3-small\":\n",
    "        return  OpenAIEmbeddings(model= model_name, dimensions=512)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model name: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ab5b128",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "model=load_model(\"gpt-4o\")\n",
    "embedding_model=load_model(\"text-embedding-3-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ab3644",
   "metadata": {},
   "source": [
    "# Parsing the PDF Document for the RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7311984d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 document(s)\n",
      "Split into 3 chunks\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "def load_and_split_text(file_path, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    Load a text file and split it into chunks for RAG processing\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the text file\n",
    "        chunk_size (int): Size of each text chunk\n",
    "        chunk_overlap (int): Overlap between chunks\n",
    "    \n",
    "    Returns:\n",
    "        list: List of document chunks\n",
    "    \"\"\"\n",
    "    # Load the text file\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    \n",
    "    # Initialize the text splitter\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]  # Try to split on paragraphs first, then sentences, then words\n",
    "    )\n",
    "    \n",
    "    # Split the documents into chunks\n",
    "    chunks = text_splitter.split_documents(documents)\n",
    "    \n",
    "    print(f\"Loaded {len(documents)} document(s)\")\n",
    "    print(f\"Split into {len(chunks)} chunks\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "# Load and split your dividend.txt file\n",
    "file_path = \"/home/ashok/agents_assignment/data/dividend.txt\"\n",
    "document_chunks = load_and_split_text(file_path, chunk_size=1000, chunk_overlap=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137ab81e",
   "metadata": {},
   "source": [
    "# DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35c571d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created vector database with 3 chunks\n"
     ]
    }
   ],
   "source": [
    "def create_vector_database(chunks, embedding_model):\n",
    "    \"\"\"\n",
    "    Create a vector database from document chunks\n",
    "    \n",
    "    Args:\n",
    "        chunks (list): List of document chunks\n",
    "        embedding_model: The embedding model to use\n",
    "    \n",
    "    Returns:\n",
    "        FAISS: Vector database\n",
    "    \"\"\"\n",
    "    # Create FAISS vector store from document chunks\n",
    "    vector_db = FAISS.from_documents(chunks, embedding_model)\n",
    "    \n",
    "    print(f\"Created vector database with {len(chunks)} chunks\")\n",
    "    return vector_db\n",
    "\n",
    "# Create vector database from the chunks\n",
    "vector_db = create_vector_database(document_chunks, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efcc69f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 3 relevant chunks for query: 'What is dividend yield of Natco pharma on february month?'\n"
     ]
    }
   ],
   "source": [
    "def retrieve_relevant_chunks(query, vector_db, k=3):\n",
    "    \"\"\"\n",
    "    Retrieve relevant document chunks based on a query\n",
    "    \n",
    "    Args:\n",
    "        query (str): The query string\n",
    "        vector_db: The vector database\n",
    "        k (int): Number of relevant chunks to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        list: List of relevant document chunks\n",
    "    \"\"\"\n",
    "    # Perform similarity search\n",
    "    relevant_docs = vector_db.similarity_search(query, k=k)\n",
    "    \n",
    "    print(f\"Retrieved {len(relevant_docs)} relevant chunks for query: '{query}'\")\n",
    "    \n",
    "    return relevant_docs\n",
    "\n",
    "# Example usage\n",
    "query = \"What is dividend yield of Natco pharma on february month?\"\n",
    "relevant_chunks = retrieve_relevant_chunks(query, vector_db, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab44613d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='6349ca61-b373-442d-8ccb-8013b9d408be', metadata={'source': '/home/ashok/agents_assignment/data/dividend.txt'}, page_content='1. Natco Pharma will pay a dividend of 15 on February 26, 2024.\\n2. Fineotex Chem will pay a dividend of 138 on February 26, 2024.\\n3. Hero Motocorp will pay a dividend of 225 on February 21, 2024.\\n4. Hero Motocorp will pay another dividend of 675 on February 21, 2024.\\n5. Apollo Hospitals will pay a dividend of 54 on February 20, 2024.\\n6. Sundaram Finance will pay a dividend of 84 on February 16, 2024.\\n7. Manappuram Finance will pay a dividend of 16.2 on February 16, 2024.\\n8. Gulf Oil Lubricants will pay a dividend of 384 on February 13, 2024.\\n9. Symphony will pay a dividend of 2 on February 7, 2024.\\n10. Shriram Finance will pay a dividend of 100 on February 6, 2024.\\n11. Goa Carbon will pay a dividend of 100 on January 29, 2024.\\n12. Natco Pharma paid a dividend of 15 on November 24, 2023.\\n13. Manappuram Finance paid a dividend of 15.3 on November 24, 2023.\\n14. Shriram Finance paid a dividend of 200 on November 6, 2023.\\n15. Symphony paid a dividend of 2 on November 3, 2023.'),\n",
       " Document(id='79f668db-f977-4491-b3a0-796618ae8baa', metadata={'source': '/home/ashok/agents_assignment/data/dividend.txt'}, page_content='13. Manappuram Finance paid a dividend of 15.3 on November 24, 2023.\\n14. Shriram Finance paid a dividend of 200 on November 6, 2023.\\n15. Symphony paid a dividend of 2 on November 3, 2023.\\n16. LTIMindtree paid a dividend of 260 on October 27, 2023.\\n17. Infosys paid a dividend of 18 on October 25, 2023.\\n18. Dalmia Bharat Ltd paid a dividend of 32 on October 20, 2023.\\n19. Multi Commodity Exchange paid a dividend of 152.72 on September 15, 2023.\\n20. Dilip Buildcon paid a dividend of 1.3 on September 11, 2023.\\n21. Fineotex Chemical paid a dividend of 92 on September 8, 2023.\\nThe record indicates that on September 1, 2023, APL Apollo Tubes, identified by the code INE702C01027, had a value of 555.'),\n",
       " Document(id='00852514-508e-46ef-894f-ebc25e8d139c', metadata={'source': '/home/ashok/agents_assignment/data/dividend.txt'}, page_content='## Profit/Loss Statement for Portfolio as on  04 Jul 2024\\n\\n\\nFrom Date\\n\\n01/APR/2023\\n\\nTo Date\\n\\n31/MAR/2024\\n\\nPortfolio\\n\\nTaxable Portfolio\\n\\nFor Asset Class\\n\\nDividend\\n\\nAccount Subtype\\n\\nDirect Transaction')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for enhanced LangGraph with tools\n",
    "!pip install requests beautifulsoup4 duckduckgo-search langchain-community langgraph langchain-core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd9e25d",
   "metadata": {},
   "source": [
    "# Corrective RAG Agent System with LangGraph StateGraph\n",
    "\n",
    "This section implements a comprehensive Corrective RAG agent system with:\n",
    "- **Retriever Node**: Retrieves relevant information from documents\n",
    "- **Grade/Evaluator Node**: Evaluate the relevancy of query and retrieved docs\n",
    "- **Query Rewriter Node**: Rewrites the user query\n",
    "- **Web Search Node**: Fetches real-time information from internet\n",
    "- **Generate Node**: generates the final output from retrieved docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf1b050",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be53d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install TavilySearchResults for web search\n",
    "!pip install tavily-python langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c2a0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Note: Set TAVILY_API_KEY environment variable for web search functionality\n",
      "You can get a free API key from https://tavily.com\n",
      "âœ… Corrective RAG imports completed!\n"
     ]
    }
   ],
   "source": [
    "# Imports for Corrective RAG Agent System\n",
    "import os\n",
    "import operator\n",
    "from typing import List, Dict, Any, TypedDict, Annotated, Sequence\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Set Tavily API Key if needed\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not TAVILY_API_KEY:\n",
    "    print(\"  Note: Set TAVILY_API_KEY environment variable for web search functionality\")\n",
    "    print(\"You can get a free API key from https://tavily.com\")\n",
    "\n",
    "print(\" Corrective RAG imports completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958924b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Corrective RAG State defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define the Corrective RAG State with Threshold Support\n",
    "class CorrectiveRAGState(TypedDict):\n",
    "    \"\"\"\n",
    "    State for the Corrective RAG Agent System with 70% threshold support\n",
    "    \"\"\"\n",
    "    # Input\n",
    "    question: str\n",
    "    \n",
    "    # Retrieved documents\n",
    "    documents: List[Document]\n",
    "    \n",
    "    # Document grading with threshold\n",
    "    documents_relevant: bool\n",
    "    grade_scores: List[str]  # \"relevant\" or \"not relevant\" for each doc\n",
    "    relevancy_percentage: float  # Percentage of relevant documents\n",
    "    threshold_met: bool  # Whether 70% threshold is met\n",
    "    \n",
    "    # Query processing\n",
    "    rewritten_question: str\n",
    "    \n",
    "    # Web search\n",
    "    web_search_needed: bool\n",
    "    web_documents: List[Document]\n",
    "    \n",
    "    # Generation\n",
    "    generation: str\n",
    "    \n",
    "    # System tracking\n",
    "    current_step: str\n",
    "    retry_count: int\n",
    "    \n",
    "    # Message history\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "\n",
    "print(\" Corrective RAG State defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d49a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Retriever Node implemented!\n"
     ]
    }
   ],
   "source": [
    "# 1. RETRIEVER NODE\n",
    "def retriever_node(state: CorrectiveRAGState) -> CorrectiveRAGState:\n",
    "    \"\"\"\n",
    "    Retrieves relevant documents from the vector database based on the question\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\" Retrieving documents for: {question}\")\n",
    "        \n",
    "        # Use the existing vector database to retrieve relevant documents\n",
    "        relevant_docs = vector_db.similarity_search(question, k=4)\n",
    "        \n",
    "        print(f\" Retrieved {len(relevant_docs)} documents\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"documents\": relevant_docs,\n",
    "            \"current_step\": \"retrieval_complete\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Retrieved {len(relevant_docs)} relevant documents\")]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in retriever node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"documents\": [],\n",
    "            \"current_step\": \"retrieval_failed\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Retrieval error: {e}\")]\n",
    "        }\n",
    "\n",
    "print(\" Retriever Node implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8546974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Grader/Evaluator Node implemented!\n"
     ]
    }
   ],
   "source": [
    "# 2. GRADE/EVALUATOR NODE WITH THRESHOLD\n",
    "def grader_node(state: CorrectiveRAGState) -> CorrectiveRAGState:\n",
    "    \"\"\"\n",
    "    Evaluates the relevancy of retrieved documents to the user question with 70% threshold\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\"ðŸ“Š Grading {len(documents)} documents for relevancy\")\n",
    "        \n",
    "        grade_scores = []\n",
    "        relevant_docs = []\n",
    "        \n",
    "        # Create grading prompt\n",
    "        grading_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a grader assessing relevance of retrieved documents to a user question.\n",
    "        \n",
    "        Retrieved document: {document}\n",
    "        \n",
    "        User question: {question}\n",
    "        \n",
    "        If the document contains information relevant to the user question, grade it as \"relevant\".\n",
    "        If the document does not contain information relevant to the user question, grade it as \"not relevant\".\n",
    "        \n",
    "        Give a binary score 'relevant' or 'not relevant' to indicate whether the document is relevant to the question.\n",
    "        \n",
    "        Provide the grade as a single word: relevant or not relevant\n",
    "        \"\"\")\n",
    "        \n",
    "        grading_chain = grading_prompt | model | StrOutputParser()\n",
    "        \n",
    "        for doc in documents:\n",
    "            # Grade each document\n",
    "            grade = grading_chain.invoke({\n",
    "                \"document\": doc.page_content,\n",
    "                \"question\": question\n",
    "            }).strip().lower()\n",
    "            \n",
    "            # Normalize the grade\n",
    "            if \"relevant\" in grade and \"not relevant\" not in grade:\n",
    "                grade_scores.append(\"relevant\")\n",
    "                relevant_docs.append(doc)\n",
    "            else:\n",
    "                grade_scores.append(\"not relevant\")\n",
    "        \n",
    "        # Calculate relevancy percentage\n",
    "        relevant_count = sum(1 for score in grade_scores if score == \"relevant\")\n",
    "        total_documents = len(documents)\n",
    "        relevancy_percentage = (relevant_count / total_documents) * 100 if total_documents > 0 else 0\n",
    "        \n",
    "        # Apply 70% threshold rule\n",
    "        threshold_met = relevancy_percentage >= 70.0\n",
    "        \n",
    "        print(f\" Grading complete: {relevant_count}/{len(documents)} documents are relevant ({relevancy_percentage:.1f}%)\")\n",
    "        print(f\" Threshold (70%): {' MET' if threshold_met else ' NOT MET'}\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"documents\": relevant_docs if threshold_met else documents,  # Keep only relevant if threshold met\n",
    "            \"documents_relevant\": threshold_met,\n",
    "            \"grade_scores\": grade_scores,\n",
    "            \"relevancy_percentage\": relevancy_percentage,\n",
    "            \"threshold_met\": threshold_met,\n",
    "            \"current_step\": \"grading_complete\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Document grading: {relevancy_percentage:.1f}% relevant ({relevant_count}/{len(documents)}), Threshold: {'Met' if threshold_met else 'Not Met'}\")]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in grader node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"documents_relevant\": False,\n",
    "            \"grade_scores\": [\"not relevant\"] * len(documents),\n",
    "            \"relevancy_percentage\": 0.0,\n",
    "            \"threshold_met\": False,\n",
    "            \"current_step\": \"grading_failed\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Grading error: {e}\")]\n",
    "        }\n",
    "\n",
    "print(\" Grader/Evaluator Node implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9de0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Query Rewriter Node implemented!\n"
     ]
    }
   ],
   "source": [
    "# 3. QUERY REWRITER NODE\n",
    "def query_rewriter_node(state: CorrectiveRAGState) -> CorrectiveRAGState:\n",
    "    \"\"\"\n",
    "    Rewrites the user query to improve retrieval results\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    \n",
    "    try:\n",
    "        print(f\" Rewriting query: {question}\")\n",
    "        \n",
    "        # Create query rewriting prompt\n",
    "        rewriting_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "        You are a query rewriter. Your task is to rewrite the user's question to improve document retrieval.\n",
    "        \n",
    "        Original question: {question}\n",
    "        \n",
    "        Rewrite this question to be more specific, clear, and likely to retrieve relevant documents.\n",
    "        Add synonyms, expand abbreviations, and make the intent clearer.\n",
    "        \n",
    "        Improved question:\n",
    "        \"\"\")\n",
    "        \n",
    "        rewriting_chain = rewriting_prompt | model | StrOutputParser()\n",
    "        \n",
    "        rewritten_question = rewriting_chain.invoke({\"question\": question}).strip()\n",
    "        \n",
    "        print(f\" Query rewritten to: {rewritten_question}\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"rewritten_question\": rewritten_question,\n",
    "            \"current_step\": \"query_rewritten\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Query rewritten: {rewritten_question}\")]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in query rewriter node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"rewritten_question\": question,  # Fallback to original question\n",
    "            \"current_step\": \"rewriting_failed\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Query rewriting error: {e}\")]\n",
    "        }\n",
    "\n",
    "print(\" Query Rewriter Node implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c9a7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Web Search Node implemented!\n"
     ]
    }
   ],
   "source": [
    "# 4. WEB SEARCH NODE\n",
    "def web_search_node(state: CorrectiveRAGState) -> CorrectiveRAGState:\n",
    "    \"\"\"\n",
    "    Performs web search using TavilySearchResults to find additional relevant information\n",
    "    \"\"\"\n",
    "    question = state.get(\"rewritten_question\", state[\"question\"])\n",
    "    \n",
    "    try:\n",
    "        print(f\"ðŸŒ Performing web search for: {question}\")\n",
    "        \n",
    "        # Initialize Tavily search (fallback if API key not available)\n",
    "        if TAVILY_API_KEY:\n",
    "            tavily_search = TavilySearchResults(\n",
    "                max_results=3,\n",
    "                search_depth=\"basic\",\n",
    "                include_answer=True,\n",
    "                include_raw_content=True\n",
    "            )\n",
    "            \n",
    "            # Perform web search\n",
    "            search_results = tavily_search.invoke({\"query\": question})\n",
    "            \n",
    "            # Convert search results to Document objects\n",
    "            web_documents = []\n",
    "            for result in search_results:\n",
    "                if isinstance(result, dict):\n",
    "                    content = result.get(\"content\", \"\")\n",
    "                    if content:\n",
    "                        web_documents.append(Document(\n",
    "                            page_content=content,\n",
    "                            metadata={\n",
    "                                \"source\": result.get(\"url\", \"web_search\"),\n",
    "                                \"title\": result.get(\"title\", \"Web Search Result\"),\n",
    "                                \"search_type\": \"tavily\"\n",
    "                            }\n",
    "                        ))\n",
    "            \n",
    "            print(f\" Found {len(web_documents)} web search results\")\n",
    "            \n",
    "        else:\n",
    "            # Fallback: Create mock web search results when Tavily API not available\n",
    "            print(\"  Tavily API key not found. Using fallback web search simulation.\")\n",
    "            web_documents = [\n",
    "                Document(\n",
    "                    page_content=f\"Web search result for '{question}'. This is a simulated result when Tavily API is not available.\",\n",
    "                    metadata={\"source\": \"fallback_search\", \"title\": \"Simulated Web Result\", \"search_type\": \"fallback\"}\n",
    "                )\n",
    "            ]\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"web_documents\": web_documents,\n",
    "            \"web_search_needed\": False,\n",
    "            \"current_step\": \"web_search_complete\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Web search completed: {len(web_documents)} results\")]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in web search node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"web_documents\": [],\n",
    "            \"web_search_needed\": False,\n",
    "            \"current_step\": \"web_search_failed\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Web search error: {e}\")]\n",
    "        }\n",
    "\n",
    "print(\" Web Search Node implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb4d425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generate Node implemented!\n"
     ]
    }
   ],
   "source": [
    "# 5. GENERATE NODE WITH COMBINED INFORMATION\n",
    "def generate_node(state: CorrectiveRAGState) -> CorrectiveRAGState:\n",
    "    \"\"\"\n",
    "    Generates the final answer using retrieved documents and/or web search results\n",
    "    Now combines RAG documents with web search information when threshold < 70%\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state.get(\"documents\", [])\n",
    "    web_documents = state.get(\"web_documents\", [])\n",
    "    threshold_met = state.get(\"threshold_met\", False)\n",
    "    relevancy_percentage = state.get(\"relevancy_percentage\", 0.0)\n",
    "    \n",
    "    try:\n",
    "        print(f\" Generating answer for: {question}\")\n",
    "        print(f\" Using: {len(documents)} RAG docs + {len(web_documents)} web docs\")\n",
    "        \n",
    "        # Combine all available documents\n",
    "        all_documents = documents + web_documents\n",
    "        \n",
    "        if not all_documents:\n",
    "            # No documents available\n",
    "            generation = \"I apologize, but I couldn't find relevant information to answer your question. Please try rephrasing your question or provide more context.\"\n",
    "        else:\n",
    "            # Create context from all documents\n",
    "            rag_context = \"\"\n",
    "            web_context = \"\"\n",
    "            \n",
    "            # Separate RAG and web content for better organization\n",
    "            if documents:\n",
    "                rag_context = \"\\n\\n\".join([\n",
    "                    f\"RAG Source {i+1}: {doc.page_content}\" \n",
    "                    for i, doc in enumerate(documents[:3])  # Limit RAG sources\n",
    "                ])\n",
    "            \n",
    "            if web_documents:\n",
    "                web_context = \"\\n\\n\".join([\n",
    "                    f\"Web Source {i+1}: {doc.page_content}\" \n",
    "                    for i, doc in enumerate(web_documents[:3])  # Limit web sources\n",
    "                ])\n",
    "            \n",
    "            # Combine contexts\n",
    "            combined_context = \"\"\n",
    "            if rag_context:\n",
    "                combined_context += f\"INTERNAL KNOWLEDGE:\\n{rag_context}\\n\\n\"\n",
    "            if web_context:\n",
    "                combined_context += f\"EXTERNAL KNOWLEDGE:\\n{web_context}\"\n",
    "            \n",
    "            # Create generation prompt with threshold information\n",
    "            generation_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "            You are an AI assistant that provides accurate and helpful answers based on the given context.\n",
    "            \n",
    "            Context information:\n",
    "            {context}\n",
    "            \n",
    "            Question: {question}\n",
    "            \n",
    "            Analysis Summary:\n",
    "            - Relevancy Score: {relevancy_percentage:.1f}%\n",
    "            - Threshold Status: {threshold_status}\n",
    "            - Information Sources: {source_info}\n",
    "            \n",
    "            Instructions:\n",
    "            1. Use both internal knowledge (RAG) and external knowledge (web search) to provide a comprehensive answer\n",
    "            2. Prioritize information from internal knowledge if it's highly relevant\n",
    "            3. Use external knowledge to supplement or provide additional context\n",
    "            4. If combining multiple sources, clearly synthesize the information\n",
    "            5. Be specific and cite information from the context when possible\n",
    "            6. Provide a clear, well-structured response\n",
    "            \n",
    "            Answer:\n",
    "            \"\"\")\n",
    "            \n",
    "            generation_chain = generation_prompt | model | StrOutputParser()\n",
    "            \n",
    "            # Determine source information\n",
    "            source_info = []\n",
    "            if documents:\n",
    "                source_info.append(f\"{len(documents)} internal documents\")\n",
    "            if web_documents:\n",
    "                source_info.append(f\"{len(web_documents)} web sources\")\n",
    "            \n",
    "            generation = generation_chain.invoke({\n",
    "                \"context\": combined_context,\n",
    "                \"question\": question,\n",
    "                \"relevancy_percentage\": relevancy_percentage,\n",
    "                \"threshold_status\": \"Met (â‰¥70%)\" if threshold_met else \"Not Met (<70%)\",\n",
    "                \"source_info\": \" + \".join(source_info) if source_info else \"No sources\"\n",
    "            }).strip()\n",
    "        \n",
    "        print(f\" Generated answer ({len(generation)} characters)\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"generation\": generation,\n",
    "            \"current_step\": \"generation_complete\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=generation)]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in generate node: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"generation\": f\"Error generating response: {e}\",\n",
    "            \"current_step\": \"generation_failed\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Generation error: {e}\")]\n",
    "        }\n",
    "\n",
    "print(\" Generate Node implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26cece3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Routing functions with threshold logic implemented!\n"
     ]
    }
   ],
   "source": [
    "# 6. ROUTING FUNCTIONS WITH THRESHOLD LOGIC\n",
    "def decide_to_grade_or_rewrite(state: CorrectiveRAGState) -> str:\n",
    "    \"\"\"\n",
    "    Determines whether to grade documents or rewrite query after retrieval\n",
    "    \"\"\"\n",
    "    documents = state.get(\"documents\", [])\n",
    "    \n",
    "    if len(documents) == 0:\n",
    "        print(\" No documents retrieved, rewriting query\")\n",
    "        return \"rewrite_query\"\n",
    "    else:\n",
    "        print(\" Documents found, proceeding to grade\")\n",
    "        return \"grade_documents\"\n",
    "\n",
    "def decide_to_generate_or_search(state: CorrectiveRAGState) -> str:\n",
    "    \"\"\"\n",
    "    Determines next step based on 70% threshold:\n",
    "    - If threshold >= 70%: Go directly to generate\n",
    "    - If threshold < 70%: Go to rewrite query, then web search, then generate\n",
    "    \"\"\"\n",
    "    threshold_met = state.get(\"threshold_met\", False)\n",
    "    relevancy_percentage = state.get(\"relevancy_percentage\", 0.0)\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "    \n",
    "    if threshold_met:\n",
    "        print(f\" Threshold met ({relevancy_percentage:.1f}% >= 70%), generating answer directly\")\n",
    "        return \"generate\"\n",
    "    else:\n",
    "        print(f\"  Threshold not met ({relevancy_percentage:.1f}% < 70%), proceeding to query rewrite and web search\")\n",
    "        return \"rewrite_query\"\n",
    "\n",
    "def decide_after_rewrite(state: CorrectiveRAGState) -> str:\n",
    "    \"\"\"\n",
    "    After rewriting query, always go to web search to gather additional information\n",
    "    \"\"\"\n",
    "    print(\" Query rewritten, performing web search for additional information\")\n",
    "    return \"web_search\"\n",
    "\n",
    "def decide_after_web_search(state: CorrectiveRAGState) -> str:\n",
    "    \"\"\"\n",
    "    After web search, always go to generate with combined information\n",
    "    \"\"\"\n",
    "    print(\" Web search completed, combining with RAG documents for final generation\")\n",
    "    return \"generate\"\n",
    "\n",
    "print(\" Routing functions with threshold logic implemented!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83720140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced Corrective RAG Agent System with 70% threshold created successfully!\n",
      "ðŸŽ¯ New Workflow:\n",
      "   ðŸ“Š If relevancy >= 70%: Retrieve â†’ Grade â†’ Generate\n",
      "   ðŸ”„ If relevancy < 70%: Retrieve â†’ Grade â†’ Rewrite â†’ Web Search â†’ Generate\n"
     ]
    }
   ],
   "source": [
    "# 7. CREATE ENHANCED CORRECTIVE RAG STATEGRAPH WITH THRESHOLD\n",
    "def create_corrective_rag_graph():\n",
    "    \"\"\"\n",
    "    Creates the Enhanced Corrective RAG Agent System with 70% threshold logic\n",
    "    \n",
    "    Workflow:\n",
    "    1. Retrieve documents from RAG\n",
    "    2. Grade documents for relevancy\n",
    "    3. If relevancy >= 70%: Go directly to Generate\n",
    "    4. If relevancy < 70%: Rewrite query â†’ Web search â†’ Generate (with combined info)\n",
    "    \"\"\"\n",
    "    # Initialize the StateGraph\n",
    "    workflow = StateGraph(CorrectiveRAGState)\n",
    "    \n",
    "    # Add nodes to the graph\n",
    "    workflow.add_node(\"retrieve\", retriever_node)\n",
    "    workflow.add_node(\"grade_documents\", grader_node)\n",
    "    workflow.add_node(\"rewrite_query\", query_rewriter_node)\n",
    "    workflow.add_node(\"web_search\", web_search_node)\n",
    "    workflow.add_node(\"generate\", generate_node)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"retrieve\")\n",
    "    \n",
    "    # Add conditional edges for retrieval routing\n",
    "    workflow.add_conditional_edges(\n",
    "        \"retrieve\",\n",
    "        decide_to_grade_or_rewrite,\n",
    "        {\n",
    "            \"grade_documents\": \"grade_documents\",\n",
    "            \"rewrite_query\": \"rewrite_query\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add conditional edges for grading routing (threshold-based)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"grade_documents\", \n",
    "        decide_to_generate_or_search,\n",
    "        {\n",
    "            \"generate\": \"generate\",           # If threshold >= 70%\n",
    "            \"rewrite_query\": \"rewrite_query\"  # If threshold < 70%\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add conditional edges for rewrite routing (always to web search)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"rewrite_query\",\n",
    "        decide_after_rewrite,\n",
    "        {\n",
    "            \"web_search\": \"web_search\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Add edges for web search and generation\n",
    "    workflow.add_edge(\"web_search\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "    \n",
    "    # Compile the graph\n",
    "    app = workflow.compile()\n",
    "    \n",
    "    return app\n",
    "\n",
    "# Create the Enhanced Corrective RAG system\n",
    "corrective_rag_app = create_corrective_rag_graph()\n",
    "\n",
    "print(\" Enhanced Corrective RAG Agent System with 70% threshold created successfully!\")\n",
    "print(\" New Workflow:\")\n",
    "print(\"    If relevancy >= 70%: Retrieve â†’ Grade â†’ Generate\")\n",
    "print(\"    If relevancy < 70%: Retrieve â†’ Grade â†’ Rewrite â†’ Web Search â†’ Generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656cb585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Enhanced Corrective RAG Agent System with 70% threshold ready!\n",
      "ðŸŽ¯ Threshold Logic: >= 70% â†’ Direct Generation | < 70% â†’ Query Rewrite + Web Search\n"
     ]
    }
   ],
   "source": [
    "# 8. ENHANCED RETRIEVER WITH RETRY LOGIC (Updated for Threshold System)\n",
    "def enhanced_retriever_node(state: CorrectiveRAGState) -> CorrectiveRAGState:\n",
    "    \"\"\"\n",
    "    Enhanced retriever that uses rewritten query and handles retries\n",
    "    \"\"\"\n",
    "    # Use rewritten question if available, otherwise use original\n",
    "    question = state.get(\"rewritten_question\", state[\"question\"])\n",
    "    retry_count = state.get(\"retry_count\", 0)\n",
    "    \n",
    "    try:\n",
    "        print(f\" Enhanced retrieval (attempt {retry_count + 1}) for: {question}\")\n",
    "        \n",
    "        # Retrieve documents using the (possibly rewritten) question\n",
    "        relevant_docs = vector_db.similarity_search(question, k=5)  # Increased to 5 for better threshold calculation\n",
    "        \n",
    "        print(f\" Retrieved {len(relevant_docs)} documents\")\n",
    "        \n",
    "        return {\n",
    "            **state,\n",
    "            \"documents\": relevant_docs,\n",
    "            \"retry_count\": retry_count + 1,\n",
    "            \"current_step\": \"retrieval_complete\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Enhanced retrieval: {len(relevant_docs)} documents\")]\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\" Error in enhanced retriever: {e}\")\n",
    "        return {\n",
    "            **state,\n",
    "            \"documents\": [],\n",
    "            \"retry_count\": retry_count + 1,\n",
    "            \"current_step\": \"retrieval_failed\",\n",
    "            \"messages\": state[\"messages\"] + [AIMessage(content=f\"Enhanced retrieval error: {e}\")]\n",
    "        }\n",
    "\n",
    "# Update the graph with enhanced retriever and threshold logic\n",
    "def create_enhanced_corrective_rag_graph():\n",
    "    \"\"\"\n",
    "    Creates enhanced Corrective RAG system with 70% threshold and better document handling\n",
    "    \"\"\"\n",
    "    workflow = StateGraph(CorrectiveRAGState)\n",
    "    \n",
    "    # Add nodes\n",
    "    workflow.add_node(\"retrieve\", enhanced_retriever_node)\n",
    "    workflow.add_node(\"grade_documents\", grader_node)\n",
    "    workflow.add_node(\"rewrite_query\", query_rewriter_node)\n",
    "    workflow.add_node(\"web_search\", web_search_node)\n",
    "    workflow.add_node(\"generate\", generate_node)\n",
    "    \n",
    "    # Set entry point\n",
    "    workflow.set_entry_point(\"retrieve\")\n",
    "    \n",
    "    # Add conditional edges with threshold logic\n",
    "    workflow.add_conditional_edges(\n",
    "        \"retrieve\",\n",
    "        decide_to_grade_or_rewrite,\n",
    "        {\n",
    "            \"grade_documents\": \"grade_documents\",\n",
    "            \"rewrite_query\": \"rewrite_query\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"grade_documents\", \n",
    "        decide_to_generate_or_search,\n",
    "        {\n",
    "            \"generate\": \"generate\",           # Threshold >= 70%\n",
    "            \"rewrite_query\": \"rewrite_query\"  # Threshold < 70%\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"rewrite_query\",\n",
    "        decide_after_rewrite,\n",
    "        {\n",
    "            \"web_search\": \"web_search\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"web_search\", \"generate\")\n",
    "    workflow.add_edge(\"generate\", END)\n",
    "    \n",
    "    return workflow.compile()\n",
    "\n",
    "# Create enhanced system with threshold\n",
    "enhanced_corrective_rag_app = create_enhanced_corrective_rag_graph()\n",
    "\n",
    "print(\" Enhanced Corrective RAG Agent System with 70% threshold ready!\")\n",
    "print(\" Threshold Logic: >= 70% â†’ Direct Generation | < 70% â†’ Query Rewrite + Web Search\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c26c9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Enhanced Corrective RAG test functions with threshold logic ready!\n",
      " Use run_corrective_rag('your question') to test individual queries\n",
      " Use test_threshold_corrective_rag_system() to run comprehensive threshold tests\n"
     ]
    }
   ],
   "source": [
    "# 9. UPDATED TEST FUNCTIONS FOR THRESHOLD-BASED CORRECTIVE RAG\n",
    "def run_corrective_rag(question: str):\n",
    "    \"\"\"\n",
    "    Run the Enhanced Corrective RAG Agent System with 70% threshold logic\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\" ENHANCED CORRECTIVE RAG AGENT SYSTEM (70% Threshold)\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Initialize state with threshold support\n",
    "    initial_state = {\n",
    "        \"question\": question,\n",
    "        \"documents\": [],\n",
    "        \"documents_relevant\": False,\n",
    "        \"grade_scores\": [],\n",
    "        \"relevancy_percentage\": 0.0,\n",
    "        \"threshold_met\": False,\n",
    "        \"rewritten_question\": \"\",\n",
    "        \"web_search_needed\": False,\n",
    "        \"web_documents\": [],\n",
    "        \"generation\": \"\",\n",
    "        \"current_step\": \"start\",\n",
    "        \"retry_count\": 0,\n",
    "        \"messages\": [HumanMessage(content=question)]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Run the Enhanced Corrective RAG system\n",
    "        final_state = enhanced_corrective_rag_app.invoke(initial_state)\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(\" ENHANCED CORRECTIVE RAG EXECUTION COMPLETED\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Display results with threshold information\n",
    "        print(f\"\\n FINAL ANSWER:\")\n",
    "        print(\"-\" * 50)\n",
    "        print(final_state.get(\"generation\", \"No answer generated\"))\n",
    "        \n",
    "        print(f\"\\n SYSTEM STATISTICS:\")\n",
    "        print(f\"   â€¢ Documents retrieved: {len(final_state.get('documents', []))}\")\n",
    "        print(f\"   â€¢ Relevancy percentage: {final_state.get('relevancy_percentage', 0.0):.1f}%\")\n",
    "        print(f\"   â€¢ Threshold (70%) status: {' MET' if final_state.get('threshold_met', False) else ' NOT MET'}\")\n",
    "        print(f\"   â€¢ Relevant documents: {sum(1 for score in final_state.get('grade_scores', []) if score == 'relevant')}\")\n",
    "        print(f\"   â€¢ Web search performed: {'Yes' if final_state.get('web_documents') else 'No'}\")\n",
    "        print(f\"   â€¢ Web documents found: {len(final_state.get('web_documents', []))}\")\n",
    "        print(f\"   â€¢ Query rewrites: {final_state.get('retry_count', 0)}\")\n",
    "        print(f\"   â€¢ Final step: {final_state.get('current_step', 'unknown')}\")\n",
    "        \n",
    "        # Show workflow path taken\n",
    "        workflow_path = \"Retrieve â†’ Grade â†’ \"\n",
    "        if final_state.get('threshold_met', False):\n",
    "            workflow_path += \"Generate (Direct - Threshold Met)\"\n",
    "        else:\n",
    "            workflow_path += \"Rewrite â†’ Web Search â†’ Generate (Combined)\"\n",
    "        print(f\"   â€¢ Workflow path: {workflow_path}\")\n",
    "        \n",
    "        return final_state\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n Error running Enhanced Corrective RAG: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "print(\" Enhanced Corrective RAG test functions with threshold logic ready!\")\n",
    "print(\" Use run_corrective_rag('your question') to test individual queries\")\n",
    "print(\" Use test_threshold_corrective_rag_system() to run comprehensive threshold tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff9134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Testing Enhanced Corrective RAG with 70% threshold logic...\n",
      "\n",
      "============================================================\n",
      "\n",
      "ðŸ§ª TEST 1: High relevancy question (should meet 70% threshold)\n",
      "------------------------------------------------------------\n",
      "\n",
      "================================================================================\n",
      " ENHANCED CORRECTIVE RAG AGENT SYSTEM (70% Threshold)\n",
      "Question: What is the dividend amount Natco pharma will pay and i want to know a brief description about natco pharma company?\n",
      "================================================================================\n",
      "\n",
      "ðŸ” Enhanced retrieval (attempt 1) for: \n",
      "âœ… Retrieved 3 documents\n",
      "ðŸ”„ Documents found, proceeding to grade\n",
      "ðŸ“Š Grading 3 documents for relevancy\n",
      "âœ… Retrieved 3 documents\n",
      "ðŸ”„ Documents found, proceeding to grade\n",
      "ðŸ“Š Grading 3 documents for relevancy\n",
      "âœ… Grading complete: 1/3 documents are relevant (33.3%)\n",
      "ðŸŽ¯ Threshold (70%): âŒ NOT MET\n",
      "âš ï¸  Threshold not met (33.3% < 70%), proceeding to query rewrite and web search\n",
      "âœï¸  Rewriting query: What is the dividend amount Natco pharma will pay and i want to know a brief description about natco pharma company?\n",
      "âœ… Grading complete: 1/3 documents are relevant (33.3%)\n",
      "ðŸŽ¯ Threshold (70%): âŒ NOT MET\n",
      "âš ï¸  Threshold not met (33.3% < 70%), proceeding to query rewrite and web search\n",
      "âœï¸  Rewriting query: What is the dividend amount Natco pharma will pay and i want to know a brief description about natco pharma company?\n",
      "âœ… Query rewritten to: What is the dividend payment amount that Natco Pharma Limited will distribute, and can you provide a brief overview or description of Natco Pharma Limited as a company?\n",
      "ðŸ”„ Query rewritten, performing web search for additional information\n",
      "ðŸŒ Performing web search for: What is the dividend payment amount that Natco Pharma Limited will distribute, and can you provide a brief overview or description of Natco Pharma Limited as a company?\n",
      "âš ï¸  Tavily API key not found. Using fallback web search simulation.\n",
      "ðŸŽ¯ Generating answer for: What is the dividend amount Natco pharma will pay and i want to know a brief description about natco pharma company?\n",
      "ðŸ“Š Using: 3 RAG docs + 1 web docs\n",
      "âœ… Query rewritten to: What is the dividend payment amount that Natco Pharma Limited will distribute, and can you provide a brief overview or description of Natco Pharma Limited as a company?\n",
      "ðŸ”„ Query rewritten, performing web search for additional information\n",
      "ðŸŒ Performing web search for: What is the dividend payment amount that Natco Pharma Limited will distribute, and can you provide a brief overview or description of Natco Pharma Limited as a company?\n",
      "âš ï¸  Tavily API key not found. Using fallback web search simulation.\n",
      "ðŸŽ¯ Generating answer for: What is the dividend amount Natco pharma will pay and i want to know a brief description about natco pharma company?\n",
      "ðŸ“Š Using: 3 RAG docs + 1 web docs\n",
      "âœ… Generated answer (720 characters)\n",
      "\n",
      "================================================================================\n",
      " ENHANCED CORRECTIVE RAG EXECUTION COMPLETED\n",
      "================================================================================\n",
      "\n",
      " FINAL ANSWER:\n",
      "--------------------------------------------------\n",
      "Natco Pharma will pay a dividend of 15 on February 26, 2024, and it also paid a dividend of 15 on November 24, 2023, as per the internal knowledge sources.\n",
      "\n",
      "Regarding a brief description of Natco Pharma Limited, it is a pharmaceutical company based in India. Natco Pharma is known for its focus on the development, manufacture, and marketing of pharmaceutical products, primarily in the areas of oncology, neurology, and gastroenterology. The company is also involved in the production of active pharmaceutical ingredients (APIs) and finished dosage formulations. Natco Pharma has a significant presence in both domestic and international markets, with a reputation for producing high-quality and affordable medications.\n",
      "\n",
      " SYSTEM STATISTICS:\n",
      "   â€¢ Documents retrieved: 3\n",
      "   â€¢ Relevancy percentage: 33.3%\n",
      "   â€¢ Threshold (70%) status:  NOT MET\n",
      "   â€¢ Relevant documents: 1\n",
      "   â€¢ Web search performed: Yes\n",
      "   â€¢ Web documents found: 1\n",
      "   â€¢ Query rewrites: 1\n",
      "   â€¢ Final step: generation_complete\n",
      "   â€¢ Workflow path: Retrieve â†’ Grade â†’ Rewrite â†’ Web Search â†’ Generate (Combined)\n",
      "âœ… Generated answer (720 characters)\n",
      "\n",
      "================================================================================\n",
      " ENHANCED CORRECTIVE RAG EXECUTION COMPLETED\n",
      "================================================================================\n",
      "\n",
      " FINAL ANSWER:\n",
      "--------------------------------------------------\n",
      "Natco Pharma will pay a dividend of 15 on February 26, 2024, and it also paid a dividend of 15 on November 24, 2023, as per the internal knowledge sources.\n",
      "\n",
      "Regarding a brief description of Natco Pharma Limited, it is a pharmaceutical company based in India. Natco Pharma is known for its focus on the development, manufacture, and marketing of pharmaceutical products, primarily in the areas of oncology, neurology, and gastroenterology. The company is also involved in the production of active pharmaceutical ingredients (APIs) and finished dosage formulations. Natco Pharma has a significant presence in both domestic and international markets, with a reputation for producing high-quality and affordable medications.\n",
      "\n",
      " SYSTEM STATISTICS:\n",
      "   â€¢ Documents retrieved: 3\n",
      "   â€¢ Relevancy percentage: 33.3%\n",
      "   â€¢ Threshold (70%) status:  NOT MET\n",
      "   â€¢ Relevant documents: 1\n",
      "   â€¢ Web search performed: Yes\n",
      "   â€¢ Web documents found: 1\n",
      "   â€¢ Query rewrites: 1\n",
      "   â€¢ Final step: generation_complete\n",
      "   â€¢ Workflow path: Retrieve â†’ Grade â†’ Rewrite â†’ Web Search â†’ Generate (Combined)\n"
     ]
    }
   ],
   "source": [
    "# 10. QUICK TEST - Demonstrating Threshold-Based Routing\n",
    "print(\" Testing Enhanced Corrective RAG with 70% threshold logic...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "print(\"\\n TEST 1: High relevancy question (should meet 70% threshold)\")\n",
    "print(\"-\" * 60)\n",
    "# Test with a question about dividends (should find relevant docs and meet threshold)\n",
    "result1 = run_corrective_rag(\"What is the dividend amount Natco pharma will pay and i want to know a brief description about natco pharma company?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aaf6685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ“‹ FINAL GENERATED OUTPUT ONLY:\n",
      "============================================================\n",
      "Natco Pharma will pay a dividend of 15 on February 26, 2024, and it also paid a dividend of 15 on November 24, 2023, as per the internal knowledge sources.\n",
      "\n",
      "Regarding a brief description of Natco Pharma Limited, it is a pharmaceutical company based in India. Natco Pharma is known for its focus on the development, manufacture, and marketing of pharmaceutical products, primarily in the areas of oncology, neurology, and gastroenterology. The company is also involved in the production of active pharmaceutical ingredients (APIs) and finished dosage formulations. Natco Pharma has a significant presence in both domestic and international markets, with a reputation for producing high-quality and affordable medications.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Extract only the final generated output from result1\n",
    "if result1:\n",
    "    final_answer = result1.get(\"generation\", \"No answer generated\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"ðŸ“‹ FINAL GENERATED OUTPUT ONLY:\")\n",
    "    print(\"=\"*60)\n",
    "    print(final_answer)\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\" No result available to extract from\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582768f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
